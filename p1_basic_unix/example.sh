The frequentist uses the concept of frequency or repeated sampling. It focuses on estimating statistical parameters, e.g. means and variances and making statistical inferences based on the given data. In frequentist statistics, parameters governing the underlying distribution are treated as fixed, unknown values, and the goal is to estimate these parameters using point estimates (e.g., maximum likelihood) or confidence intervals. For example, in the Stern-Gerlach experiment, the underlining distribution is \textit{assumed} to be the binomial distribution and the controlling parameter is A. The frequentist approach does not incorporate prior beliefs on the parameter p (it is given and fixed), and it relies solely on the data at hand.
Bayesian inference treats both observed data and parameters as random variables with probability distributions, in contrast to the frequentist approach. Bayesian inference typically begins with prior beliefs or knowledge about the controlling parameters. For instance, in the Stern-Gerlach experiment, one might assume a prior probability distribution for the parameter p such as a uniform distribution. The likelihood function quantifies the probability of observing the data with a specific set of controlling parameters and often relies on certain assumptions. For example, it might be described by a binomial distribution with the controlling parameter p in the Stern-Gerlach experiment. The posterior probability represents the updated beliefs about controlling parameters after integrating the observed data. It can then be employed as the new prior for subsequent observations, enabling the continuous refinement of beliefs in the presence of additional data.
